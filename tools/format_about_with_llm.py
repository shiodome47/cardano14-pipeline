# tools/format_about_with_llm.py

import json
import time
from pathlib import Path

from openai import OpenAI  # pip install openai>=1.0.0

client = OpenAI()  # API key „ÅØÁí∞Â¢ÉÂ§âÊï∞„Åã„ÇâË™≠„ÇÄ

DATA_DIR = Path("data")
INPUT_FILE = DATA_DIR / "f14_proposals_en.json"
BACKUP_FILE = DATA_DIR / "f14_proposals_en.before_structured.json"

MAX_PROPOSALS = 10  # ‰∏ÄÂ∫¶„Å´Âá¶ÁêÜ„Åô„ÇãÊúÄÂ§ß‰ª∂Êï∞

SYSTEM_PROMPT = """You are an assistant that restructures long, messy proposal form text
from Project Catalyst into a clean, readable Markdown document.
You MUST keep the meaning accurate, but improve structure and readability.
"""

USER_PROMPT_PREFIX = """
‰ª•‰∏ã„ÅÆËã±Ë™û„ÉÜ„Ç≠„Çπ„Éà„ÅØ„ÄÅProject Catalyst „ÅÆÊèêÊ°à„Éï„Ç©„Éº„É†„Åã„Çâ„Ç≥„Éî„Éö„Åó„Åü„ÄåÂ£Å„ÉÜ„Ç≠„Çπ„Éà„Äç„Åß„Åô„ÄÇ
ÊÑèÂë≥„ÅØÂ§â„Åà„Åö„Å´„ÄÅË¶ã„ÇÑ„Åô„ÅÑË¶ÅÁ¥Ñ„Éâ„Ç≠„É•„É°„É≥„Éà„Å´Êï¥ÂΩ¢„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ

Âá∫Âäõ„Éï„Ç©„Éº„Éû„ÉÉ„Éà„ÅÆ„É´„Éº„É´„ÅØÊ¨°„ÅÆÈÄö„Çä„Åß„ÅôÔºö

ÊúÄÂàù„Å´„Äå## üìå Proposal Overview„Äç„Çª„ÇØ„Ç∑„Éß„É≥„Çí‰Ωú„Çä„ÄÅ

- Category
- Title
- Requested Budget
- Duration
- Original Language
- Open Source (License)

„ÇíÁÆáÊù°Êõ∏„Åç„Åß„Åæ„Å®„ÇÅ„Çã„ÄÇ

Ê¨°„Å´„ÄÅ‰ª•‰∏ã„ÅÆË¶ãÂá∫„Åó„ÇíÈ†ÜÁï™„Å´‰Ωú„ÇãÔºö

## 1. Problem Statement
## 2. Proposed Solution
## 3. Collaborations & Team
## 4. Expected Impact
## 5. Key Performance Metrics (KPIs)
## 6. Milestones (Summary Table)
## 7. Budget Breakdown
## 8. Value for Money

ÂÜÖÂÆπ„ÅØË¶ÅÁ¥ÑÔºãÊï¥ÁêÜ„ÇíÂÑ™ÂÖà„Åó„ÄÅÁÆáÊù°Êõ∏„Åç„ÇÑÁü≠„ÅÑÊÆµËêΩ„Å´„Åæ„Å®„ÇÅ„Çã„ÄÇ
Milestones „ÅØ Markdown Ë°®ÂΩ¢Âºè„Å´„Åô„Çã„ÄÇ

„Åß„ÅØÊ¨°„ÅÆÂ£Å„ÉÜ„Ç≠„Çπ„Éà„ÇíÊï¥„Åà„Å¶„Åè„Å†„Åï„ÅÑÔºö
"""


def call_llm(wall_text: str) -> str:
    """LLM „ÅßÊï¥ÂΩ¢„Åï„Çå„Åü Markdown „ÇíÁîüÊàê„Åô„Çã."""
    prompt = USER_PROMPT_PREFIX + "\n" + wall_text

    resp = client.chat.completions.create(
        model="gpt-4.1-mini",
        temperature=0.3,
        messages=[
            {"role": "system", "content": SYSTEM_PROMPT},
            {"role": "user", "content": prompt},
        ],
    )

    return resp.choices[0].message.content.strip()


def main():
    print("[format_about] START")

    if not INPUT_FILE.exists():
        raise FileNotFoundError(INPUT_FILE)

    # JSON Ë™≠„ÅøËæº„Åø
    with INPUT_FILE.open("r", encoding="utf-8") as f:
        data = json.load(f)

    # ÂàùÂõû„ÅÆ„Åø„Éê„ÉÉ„ÇØ„Ç¢„ÉÉ„Éó
    if not BACKUP_FILE.exists():
        with BACKUP_FILE.open("w", encoding="utf-8") as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        print(f"[format_about] Backup created: {BACKUP_FILE}")

    updated = 0

    for item in data:
        pid = item.get("proposal_id")

        about_raw = item.get("full_text_en", "").strip()

        # full_text_en „ÅåÁ©∫„Å™„Çâ skip
        if not about_raw:
            print(f"- {pid}: no full_text_en, skip")
            continue

        # structured „ÅåÊó¢„Å´„ÅÇ„Çå„Å∞ skip
        if item.get("about_structured_en"):
            print(f"- {pid}: already has about_structured_en, skip")
            continue

        print(f"- {pid}: calling LLM...")

        try:
            formatted = call_llm(about_raw)
        except Exception as e:
            print(f"  ‚ùå error: {e}")
            continue

        item["about_structured_en"] = formatted
        updated += 1

        time.sleep(1)

        if updated >= MAX_PROPOSALS:
            print(f"[format_about] Reached MAX_PROPOSALS={MAX_PROPOSALS}, stopping.")
            break

    # JSON Êõ∏„ÅçÊàª„Åó
    with INPUT_FILE.open("w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)

    print(f"[format_about] Done. Updated {updated} proposals.")


if __name__ == "__main__":
    main()
