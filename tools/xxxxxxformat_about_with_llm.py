# tools/format_about_with_llm.py

import json
import time
from pathlib import Path

from openai import OpenAI  # pip install openai>=1.0.0

client = OpenAI()  # API key „ÅØÁí∞Â¢ÉÂ§âÊï∞„Åã„ÇâË™≠„ÇÄ

DATA_DIR = Path("data")
INPUT_FILE = DATA_DIR / "f14_proposals_en.json"
BACKUP_FILE = DATA_DIR / "f14_proposals_en.before_structured.json"

# ‰∏ÄÂ∫¶„Å´Êñ∞„Åó„ÅèÊï¥ÂΩ¢„Åô„ÇãÊúÄÂ§ß‰ª∂Êï∞
MAX_PROPOSALS = 3

SYSTEM_PROMPT = """You are an assistant that restructures long, messy proposal form text
from Project Catalyst into a clean, readable Markdown document.
You MUST keep the meaning accurate, but improve structure and readability.
"""

USER_PROMPT_PREFIX = """
‰ª•‰∏ã„ÅÆËã±Ë™û„ÉÜ„Ç≠„Çπ„Éà„ÅØ„ÄÅProject Catalyst „ÅÆÊèêÊ°à„Éï„Ç©„Éº„É†„Åã„ÇâÊäú„ÅçÂá∫„Åó„ÅüÂÜÖÂÆπ„Åß„Åô„ÄÇ
ÊÑèÂë≥„ÅØÂ§â„Åà„Åö„Å´„ÄÅË¶ã„ÇÑ„Åô„ÅÑË¶ÅÁ¥Ñ„Éâ„Ç≠„É•„É°„É≥„Éà„Å´Êï¥ÂΩ¢„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ

Âá∫Âäõ„Éï„Ç©„Éº„Éû„ÉÉ„Éà„ÅÆ„É´„Éº„É´„ÅØÊ¨°„ÅÆÈÄö„Çä„Åß„ÅôÔºö

ÊúÄÂàù„Å´„Äå## üìå Proposal Overview„Äç„Çª„ÇØ„Ç∑„Éß„É≥„Çí‰Ωú„Çä„ÄÅ

- Category
- Title
- Requested Budget
- Duration
- Original Language
- Open Source (License)

„ÇíÁÆáÊù°Êõ∏„Åç„Åß„Åæ„Å®„ÇÅ„Çã„ÄÇ

Ê¨°„Å´„ÄÅ‰ª•‰∏ã„ÅÆË¶ãÂá∫„Åó„ÇíÈ†ÜÁï™„Å´‰Ωú„ÇãÔºö

## 1. Problem Statement
## 2. Proposed Solution
## 3. Collaborations & Team
## 4. Expected Impact
## 5. Key Performance Metrics (KPIs)
## 6. Milestones (Summary Table)
## 7. Budget Breakdown
## 8. Value for Money

ÂÜÖÂÆπ„ÅØË¶ÅÁ¥ÑÔºãÊï¥ÁêÜ„ÇíÂÑ™ÂÖà„Åó„ÄÅÁÆáÊù°Êõ∏„Åç„ÇÑÁü≠„ÅÑÊÆµËêΩ„Å´„Åæ„Å®„ÇÅ„Çã„ÄÇ
Milestones „ÅØ Markdown Ë°®ÂΩ¢Âºè„Å´„Åô„Çã„ÄÇ

„Åß„ÅØÊ¨°„ÅÆ„ÉÜ„Ç≠„Çπ„Éà„ÇíÊï¥„Åà„Å¶„Åè„Å†„Åï„ÅÑÔºö
"""


def build_wall_text(item: dict) -> str:
    """
    proposal „ÅÆÂêÑ *_en „Éï„Ç£„Éº„É´„Éâ„Åã„Çâ 'Â£Å„ÉÜ„Ç≠„Çπ„Éà' „ÇíÁµÑ„ÅøÁ´ã„Å¶„Çã„ÄÇ

    - title_en / summary_en / about_structured_en „ÅØÈô§Â§ñ
    - ÊÆã„Çä„ÅÆ *_en „Çí„Åæ„Å®„ÇÅ„Å¶ LLM „Å´Êäï„Åí„Çã
    """
    parts: list[str] = []

    # Êú´Â∞æ„Åå _en „ÅÆ„Ç≠„Éº„ÇíÁ∑è„Åñ„Çâ„ÅÑÔºà„É°„Çø„Å£„ÅΩ„ÅÑ„ÇÇ„ÅÆ„ÅØÈô§Â§ñÔºâ
    ignore_keys = {"title_en", "summary_en", "about_structured_en"}
    en_keys: list[str] = []

    for key, value in item.items():
        if not isinstance(value, str):
            continue
        if not key.endswith("_en"):
            continue
        if key in ignore_keys:
            continue
        if not value.strip():
            continue
        en_keys.append(key)

    if not en_keys:
        return ""

    # ÂÆâÂÆö„ÅÆ„Åü„ÇÅ„ÄÅ„ÇΩ„Éº„Éà„Åó„Å¶„Åã„ÇâÁµêÂêà
    for key in sorted(en_keys):
        label_base = key[:-3]  # "_en" „ÇíÂèñ„Çã
        # ‰æã: "problem_statement" ‚Üí "Problem Statement"
        label = label_base.replace("_", " ").title()
        val = item[key].strip()
        parts.append(f"{label}:\n{val}\n")

    return "\n".join(parts).strip()


def call_llm(wall_text: str) -> str:
    """LLM „ÅßÊï¥ÂΩ¢„Åï„Çå„Åü Markdown „ÇíÁîüÊàê„Åô„Çã."""
    prompt = USER_PROMPT_PREFIX + "\n" + wall_text

    resp = client.chat.completions.create(
        model="gpt-4.1-mini",
        temperature=0.3,
        messages=[
            {"role": "system", "content": SYSTEM_PROMPT},
            {"role": "user", "content": prompt},
        ],
    )

    return resp.choices[0].message.content.strip()


def main():
    print("[format_about] START")

    if not INPUT_FILE.exists():
        raise FileNotFoundError(INPUT_FILE)

    # JSON Ë™≠„ÅøËæº„Åø
    with INPUT_FILE.open("r", encoding="utf-8") as f:
        data = json.load(f)

    # ÂàùÂõû„ÅÆ„Åø„Éê„ÉÉ„ÇØ„Ç¢„ÉÉ„Éó
    if not BACKUP_FILE.exists():
        with BACKUP_FILE.open("w", encoding="utf-8") as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        print(f"[format_about] Backup created: {BACKUP_FILE}")

    updated = 0

    for item in data:
        pid = item.get("proposal_id")

        # „Åô„Åß„Å´ structured „Åå„ÅÇ„Çã„Å™„Çâ„Çπ„Ç≠„ÉÉ„ÉóÔºàÂÜçÂÆüË°å„Å´ÂÇô„Åà„ÅüË®≠Ë®àÔºâ
        if item.get("about_structured_en"):
            print(f"- {pid}: already has about_structured_en, skip")
            continue

        wall_text = build_wall_text(item)

        # ÂÖ•Âäõ„Å´„Å™„Çã„ÉÜ„Ç≠„Çπ„Éà„Åå‰Ωï„ÇÇ„Å™„Åë„Çå„Å∞„Çπ„Ç≠„ÉÉ„Éó
        if not wall_text:
            print(f"- {pid}: no usable *_en fields, skip")
            continue

        print(f"- {pid}: calling LLM...")

        try:
            formatted = call_llm(wall_text)
        except Exception as e:
            print(f"  ‚ùå error: {e}")
            continue

        item["about_structured_en"] = formatted
        updated += 1

        time.sleep(1)

        if updated >= MAX_PROPOSALS:
            print(f"[format_about] Reached MAX_PROPOSALS={MAX_PROPOSALS}, stopping.")
            break

    # JSON Êõ∏„ÅçÊàª„Åó
    with INPUT_FILE.open("w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)

    print(f"[format_about] Done. Updated {updated} proposals.")


if __name__ == "__main__":
    main()
